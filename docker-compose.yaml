# Copyright VMware, Inc.
# SPDX-License-Identifier: APACHE-2.0

version: '3.7'

services:
  db:
    image: postgres
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME}
    ports:
      - "5432:5432"
    networks:
      - spark-network
  adminer:
    image: adminer
    restart: always
    ports:
      - 8089:8080
    networks:
      - spark-network


  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - AWS_ACCESS_KEY_ID=sadf
      - AWS_ACCESS_KEY=sadf
      - AWS_SECRET_KEY=asdf
      - AWS_SECRET_ACCESS_KEY=asdf
    ports:
      - '8080:8080'
      - '7078:7077'
    networks:
      - spark-network

  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - AWS_ACCESS_KEY_ID=asdf
      - AWS_ACCESS_KEY=asdf
      - AWS_SECRET_KEY=asdf
      - AWS_SECRET_ACCESS_KEY=asdf
    networks:
      - spark-network


  python-app:
    build:
      context: .
      dockerfile: Dockerfile.app
    command: ["5"]
    environment:
      LOGGER_HOST: logstash
      LOGGER_PORT: 5044
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      DB_HOST: db
      BUCKET_NAME: ${BUCKET_NAME}
      PREFIX_LIST: 0/, 1/
      APP_ENV: production
    networks:
      - spark-network
    depends_on:
      - db
      - elasticsearch
      - kibana
      - logstash
      - spark-master
      - spark-worker


  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.1
    container_name: elasticsearch
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
    networks:
      - spark-network

  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.1
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - spark-network

  logstash:
    image: docker.elastic.co/logstash/logstash:7.15.1
    container_name: logstash
    volumes:
      - ./logstash:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
    environment:
      - "ES_HOST=elasticsearch"
      - "ES_PORT=9200"
    networks:
      - spark-network

  localstack:
    image: localstack/localstack
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3,dynamodb,sqs
      - DEFAULT_REGION=us-east-1
      - DATA_DIR=/tmp/localstack/data
    networks:
      - spark-network

networks:
  spark-network:
    driver: bridge